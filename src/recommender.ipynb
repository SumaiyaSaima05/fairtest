{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imp\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import numpy2ri\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "numpy2ri.activate()\n",
    "ro.r('set.seed({})'.format(RANDOM_SEED))\n",
    "\n",
    "import fairtest.utils.log as fairtest_log\n",
    "imp.reload(fairtest_log)\n",
    "fairtest_log.set_params(filename='fairtest.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fairtest.utils.prepare_data as prepare\n",
    "from fairtest import DataSource\n",
    "import fairtest.investigation as inv\n",
    "import fairtest.testing as testing\n",
    "import fairtest.discovery as discovery\n",
    "import fairtest.error_profiling as error_profiling\n",
    "import fairtest.modules.metrics as metrics\n",
    "import fairtest.modules.metrics.correlation as correlation\n",
    "import fairtest.modules.metrics.regression as regression\n",
    "import fairtest.modules.metrics.binary_metrics as binary_metrics\n",
    "import fairtest.modules.statistics.confidence_interval as intervals\n",
    "import ast\n",
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "\n",
    "dataname = 'movies'\n",
    "\n",
    "# Testing Investigation on Movie Ratings\n",
    "data = prepare.data_from_csv( '../data/recommender/recommendations.txt', sep='\\\\t')\n",
    "\n",
    "# discretize age field\n",
    "data['Age'] = map(lambda a: 10 if a == 1 \n",
    "                       else 20 if a == 18 \n",
    "                       else 30 if a == 25 \n",
    "                       else 40 if a == 35 \n",
    "                       else 50 if a == 45 or a == 50\n",
    "                       else 60 if a == 56 else None, data['Age'])\n",
    "\n",
    "# discretize ratings\n",
    "data['Avg Seen Rating'] = ['low' if x < np.mean(data['Avg Seen Rating']) \n",
    "                               else 'high' for x in data['Avg Seen Rating']]\n",
    "\n",
    "data_source = DataSource(data)\n",
    "\n",
    "\n",
    "#\n",
    "# Test of associations on movie popularity\n",
    "#\n",
    "SENS = ['Gender', 'Age']\n",
    "TARGET = 'Avg Recommended Rating'\n",
    "EXPL = []\n",
    "\n",
    "test_ratings = testing.Testing(data_source, SENS, TARGET, EXPL, random_state=RANDOM_SEED,\n",
    "                               to_drop=['RMSE', 'Avg Movie Age', 'Types', 'Avg Seen Rating'])\n",
    "\n",
    "#\n",
    "# Test of associations on movie popularity conditioned on previously rated movies\n",
    "#\n",
    "SENS = ['Gender', 'Age']\n",
    "TARGET = 'Avg Recommended Rating'\n",
    "EXPL = ['Avg Seen Rating']\n",
    "\n",
    "test_ratings_expl = testing.Testing(data_source, SENS, TARGET, EXPL, random_state=RANDOM_SEED,\n",
    "                               to_drop=['RMSE', 'Avg Movie Age', 'Types'])\n",
    "\n",
    "investigations = [test_ratings, test_ratings_expl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fairtest.modules.context_discovery.guided_tree as guided_tree\n",
    "imp.reload(guided_tree)\n",
    "inv.train(investigations, score_aggregation='avg', min_leaf_size=100, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fairtest.modules.statistics.hypothesis_test as tests\n",
    "import fairtest.modules.statistics.multiple_testing as multitest\n",
    "import fairtest.modules.context_discovery.tree_parser as tree_parser\n",
    "import fairtest.modules.statistics.confidence_interval as intervals\n",
    "imp.reload(tests)\n",
    "imp.reload(multitest)\n",
    "imp.reload(tree_parser)\n",
    "imp.reload(intervals)\n",
    "\n",
    "inv.test(investigations, exact=True, prune_insignificant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fairtest.modules.bug_report.report as rep\n",
    "import fairtest.modules.bug_report.filter_rank as fr\n",
    "imp.reload(rep)\n",
    "imp.reload(fr)\n",
    "\n",
    "output_dir = '../results'\n",
    "#output_dir = None\n",
    "inv.report(investigations, dataname, filter_conf=0.95, output_dir=None, node_filter=fr.FILTER_BETTER_THAN_ANCESTORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
